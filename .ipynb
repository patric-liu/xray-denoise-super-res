{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import getdata\n",
    "import pickle\n",
    "import numpy as np \n",
    "import autoencoder as model\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "flatten = False      #False for 2D images, True for flattened ones\n",
    "denoise_only = False #False for 128x128 output, True for 64x64 output\n",
    "rescale = True       #True for [0,255] data, False for [1,0] data\n",
    "amount = 0           #amount of training data to load, 0 for all data\n",
    "train_x, train_y = getdata.get_training(flatten = flatten, amount = amount, rescale = rescale, denoise_only = denoise_only)\n",
    "test_data = getdata.get_test(flatten = flatten, amount = amount, rescale = rescale, denoise_only = denoise_only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images if flatten = True\n",
    "n=0\n",
    "for data in train_x[n:n+2]:\n",
    "    size = int(np.shape(data)[0]**(1/2))\n",
    "    plt.imshow(data.reshape(size,size), cmap = 'Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images if flatten = False\n",
    "n=0\n",
    "for data in train_y[n:n+4]:\n",
    "    data = data[:,:,0]\n",
    "    plt.imshow(data, cmap = 'Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished building autoencoder\n"
     ]
    }
   ],
   "source": [
    "# create network architecture\n",
    "# test 0 is autoencoder\n",
    "# test 1 is small convolutional network\n",
    "# test 2 is large convolutional network\n",
    "# test 3 is a deconvolutional network which scales up\n",
    "# Since we are using a large convolutional network, do not adjust the following line:\n",
    "autoencoder = model.Autoencoder([(64,64,1),(4,3)], (4,3), [(1,3)], test = 4)\n",
    "print(\"finished building autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Autoencoder' object has no attribute 'autoencoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7d4294ab3b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (1) #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TRAIN THE AUTOENCODER NORMALLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Classes/CS_446/Project/autoencoder.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, epochs, batch_size, verbose, optimizer, loss)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mdecoder_layers_lat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdecoder_layers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_layer_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                         \u001b[0mdecoder_layers_lat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layers_lat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_layer_placeholder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_layers_lat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Autoencoder' object has no attribute 'autoencoder'"
     ]
    }
   ],
   "source": [
    "# (1) #\n",
    "# TRAIN THE AUTOENCODER NORMALLY\n",
    "autoencoder.train(train_x,train_y, epochs = 4, verbose = 1, loss = 'mean_squared_error', optimizer= 'adadelta', batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test if Flatten = True\n",
    "\n",
    "# load and show custom image\n",
    "user_array = scipy.ndimage.imread('train.png', flatten=True, mode=None)\n",
    "user_array = 1-(user_array/225)\n",
    "shape = np.shape(user_array)\n",
    "imgplot = plt.imshow(user_array, cmap = 'Greys')\n",
    "plt.show()\n",
    "# compute and show reconstruction\n",
    "input_vector = user_array.flatten()\n",
    "output_vector = autoencoder.predict(np.array([input_vector, input_vector]))[0]\n",
    "output_array = output_vector.reshape(64,64)\n",
    "imgplot = plt.imshow(output_array, cmap = 'Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TEST NETOWORK for flatten = False\n",
    "\n",
    "# image number [1...5]\n",
    "num = 5\n",
    "# load and show custom image\n",
    "user_array = scipy.ndimage.imread('x' + str(num) + '.png', flatten=True, mode=None)\n",
    "user_array = 1-(user_array/225)\n",
    "imgplot = plt.imshow(user_array, cmap = 'Greys')\n",
    "plt.show()\n",
    "# load and show target image\n",
    "target = scipy.ndimage.imread('y'+ str(num) + '.png', flatten=True, mode=None)\n",
    "target = 1-(target/225)\n",
    "if denoise_only:\n",
    "    target = cv2.resize(target,(64,64))\n",
    "imgplot = plt.imshow(target, cmap = 'Greys')\n",
    "plt.show()\n",
    "# compute and show reconstruction\n",
    "input_vector = np.expand_dims(user_array, axis = 3)\n",
    "output_vector = autoencoder.predict(np.array([input_vector, input_vector]))[0]\n",
    "output_array = output_vector[:,:,0]\n",
    "imgplot = plt.imshow(output_array, cmap = 'Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING CURRENTLY\n",
    "\n",
    "# (2) #\n",
    "# INCREMENTALY TEST ON MNIST DATA\n",
    "import mnist_loader\n",
    "# load training data\n",
    "num_digits = 10\n",
    "val_data = np.array(list(map(lambda x: np.squeeze(x), np.array(list(validation_data))[:,0])))\n",
    "np.random.shuffle(val_data)\n",
    "val_data = val_data[0:num_digits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOT WORKING CURRENTLY\n",
    "\n",
    "# TRAIN AUTOENCODER AND PRINT RESULT\n",
    "epochs = 20\n",
    "\n",
    "plt.figure(figsize=(2*num_digits, 4))\n",
    "for i in range(num_digits):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, num_digits, i + 1)\n",
    "    plt.imshow(val_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train(training_data, test_data, epochs = 1, verbose = 0)\n",
    "    predicted_imgs = autoencoder.predict(val_data)\n",
    "    # copypasta code to display digits\n",
    "    plt.figure(figsize=(2*num_digits, 4))\n",
    "    for i in range(num_digits):\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, num_digits, i + 1 + num_digits)\n",
    "        plt.imshow(predicted_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(2*num_digits, 4))\n",
    "for i in range(num_digits):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, num_digits, i + 1)\n",
    "    plt.imshow(val_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "    \n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "\n",
    "import os\n",
    "from keras.models import model_from_json\n",
    "save_path = os.getcwd() + '/model_weights/deconv2.h5'\n",
    "\n",
    "autoencoder.autoencoder.save_weights(save_path)\n",
    "with open(os.getcwd() + '/model_weights/model_architecture_deconv2.json', 'w') as f:\n",
    "    f.write(autoencoder.autoencoder.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD MODEL\n",
    "\n",
    "# model reconstruction from JSON\n",
    "with open(os.getcwd() + '/model_weights/model_architecture3.json', 'r') as f:\n",
    "    autoencoder = model_from_json(f.read())\n",
    "# load weights into the model\n",
    "autoencoder.load_weights(os.getcwd() + '/model_weights/model_v3.h5')\n",
    "\n",
    "autoencoder.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
