{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import getdata\n",
    "import numpy as np \n",
    "import network\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import model_from_json, Model\n",
    "from keras.losses import mean_squared_error as loss\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "flatten = False      # Get 1D data\n",
    "rescale = True       #  Rescale 'RGB' values from [0,255] to [1,0]\n",
    "denoise_only = False # Reshape target values from 128x128 to 64x64\n",
    "amount = 0        # Amount of data to load, 0 gives loads all data\n",
    "train_x, train_y = getdata.get_training(flatten = flatten, rescale = rescale, amount = amount, denoise_only = denoise_only)\n",
    "test_data, rng = getdata.get_test(flatten = flatten, rescale = rescale, denoise_only = denoise_only, amount = amount if amount < 4000 else 3999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 4)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 8)       296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 1)       73        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 1)       10        \n",
      "=================================================================\n",
      "Total params: 419\n",
      "Trainable params: 419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "model_name = 'deconv1'\n",
    "\n",
    "# model reconstruction from JSON\n",
    "net = network.Network(None, None, None, test = 0)\n",
    "with open(os.getcwd() + '/model_weights/'+ model_name +'_architecture.json', 'r') as f:\n",
    "    net.network = model_from_json(f.read())\n",
    "# load weights into the model\n",
    "net.network.load_weights(os.getcwd() + '/model_weights/'+ model_name +'_weights.h5')\n",
    "\n",
    "net.network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Errors if indices not available\n",
    "y_true = K.variable(train_y)\n",
    "predictions = net.predict(train_x)\n",
    "y_pred = K.variable(predictions)\n",
    "del predictions\n",
    "error = np.expand_dims(K.eval(loss(y_true, y_pred)), axis=3)\n",
    "del y_true, y_pred, train_y, train_x\n",
    "mean_error = np.squeeze(np.mean(error,(1,2)))\n",
    "del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Error Indices\n",
    "ind = np.argpartition(mean_error, -10)[-10:]\n",
    "with open('error_indices.pkl', 'wb') as output:\n",
    "    pickle.dump(ind, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Error Indices\n",
    "with open('error_indices.pkl', 'rb') as input:\n",
    "\tind = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Error\n",
    "amount = 10\n",
    "ind_ = ind[4] # [0.25, 0.1, 0.05, 0.01, 0.001, 0.0001]\n",
    "# get predictions\n",
    "indexes = np.random.choice(ind_, amount, replace=False)\n",
    "print(indexes)\n",
    "predictions = net.predict(np.take(train_x, indexes, axis = 0))\n",
    "# get error\n",
    "error = np.expand_dims(K.eval(loss(K.variable(np.take(train_y, \\\n",
    "            indexes, axis = 0)), K.variable(predictions))), axis=3)\n",
    "# mean error * e4\n",
    "print(np.squeeze(np.mean(error,(1,2)))*1e4)\n",
    "\n",
    "# show heatmap of images with the most error\n",
    "print('inputs > outputs > target > error')\n",
    "plotrow(train_x, indexes)\n",
    "plotrow(predictions, list(range(len(indexes))))\n",
    "plotrow(train_y, indexes)\n",
    "plotrow(error, list(range(len(indexes))), 0, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotrow(img_array, indexes, vmin = 0, vmax = 1):\n",
    "    amount_ = len(indexes)\n",
    "    plt.figure(figsize=(3*amount_, 6))\n",
    "    for n,i in enumerate(indexes):\n",
    "        ax = plt.subplot(2, amount_, n + 1)\n",
    "        plt.imshow(np.squeeze(img_array[i],2), cmap = 'Greys', vmin = vmin, vmax = vmax)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Error Indices\n",
    "with open('mean_error.pkl', 'rb') as input:\n",
    "\tmean_errors = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = {}\n",
    "for idx, error in enumerate(mean_errors):\n",
    "    idx = idx + 4000\n",
    "    error = round(error,10)\n",
    "    if error not in real_images:\n",
    "        real_images[error] = [idx]\n",
    "    else:\n",
    "        real_images[error].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 8370, 2: 2607, 3: 613, 4: 98, 5: 31, 6: 5}\n"
     ]
    }
   ],
   "source": [
    "repeats = {}\n",
    "for key, value in real_images.items():\n",
    "    num = len(value)\n",
    "    if num not in repeats:\n",
    "        repeats[num] = 1\n",
    "    else:\n",
    "        repeats[num] += 1\n",
    "print(repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5132, 8740, 9955, 14000, 15514, 16764]\n",
      "[4246, 6272, 6707, 12247, 13959, 14521]\n",
      "[4219, 9960, 15064, 18076, 18561, 19588]\n",
      "[7173, 7969, 11636, 13122, 13712, 18684]\n",
      "[5668, 6331, 6421, 10609, 14427, 18485]\n"
     ]
    }
   ],
   "source": [
    "for key, value in real_images.items():\n",
    "    if len(value) == 6:\n",
    "        print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
